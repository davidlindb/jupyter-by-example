{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d6bf4024-f4ad-4c8d-98b0-74fd3c09ac4a",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# JupyterHub Showcase: DevOps Intelligence\n",
    "\n",
    "<img src=\"img/jhub-devops-intelligence.png\" style=\"width: 95%; margin: 0;\"></img>\n",
    "\n",
    "<img src=\"https://avatars3.githubusercontent.com/u/1068245?s=40\" alt=\"Avatar\" style=\"float: left; padding-right:1rem; padding-bottom:.5rem;\"></img>\n",
    "📝 [Jürgen Hermann](https://twitter.com/jhermann_) · 📧 jh@web.de\n",
    "<br />🗓️ March 2019\n",
    "\n",
    "*DevOps Intelligence* turns data from software development and delivery processes into actionable insight, just like BI does for the business side. Jupyter is the ideal instrument for that, with its combination of powerful coding environments and a user interface facilitating experimentation with ultra-short feedback cycles.\n",
    "<img src=\"img/jhub-logo-342px.png\" style=\"float: right; padding-left: 1em;\"></img>\n",
    "\n",
    "A Jupyter-based setup supports risk analysis and decision making within development and operations processes – typical business intelligence / data science procedures can be applied to the ‘business of making and running software’. The idea is to create feedback loops, and facilitate human decision making by automatically providing reliable input in form of up-to-date facts. After all development is our business — so let's have KPIs for developing, releasing, and operating software."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "199d32ef-6caf-47af-9c6b-00d4e2027b2b",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Typical Use-Cases\n",
    "\n",
    "Here are some obvious application areas where data analysis can be helpful on the technical side.\n",
    "\n",
    "* Migration processes of all kinds (current state, progress tracking, achievement of objectives)\n",
    "* Inventory reporting for increased transparency and support of operational decisions\n",
    "* Automate internal reporting processes to free up scarce assets and human expertise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0e4ea2a8-a961-4254-9775-3245be4d0f4b",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Platform Architecture\n",
    "\n",
    "A simple [JupyterHub](https://jupyter.org/hub) setup can enable you to do analysis on your already available but under-used and hardly understood data, without any great investment of effort or capital. By adding a single JupyterHub host, you can use the built-in Python3 kernel to access existing internal data sources.\n",
    "\n",
    "The following diagram shows what role JupyterHub can play in an existing environment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "15d2e954-d002-4a5e-becc-31f481918bdf",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "> ![DevOps Intelligence Architecture](https://github.com/1and1/debianized-jupyterhub/raw/master/docs/_static/img/devops-intelligence.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "af6e2495-80a3-45e5-9c31-1bf5104ba984",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "To make such a deployment easy, the [1and1/debianized-jupyterhub](https://github.com/1and1/debianized-jupyterhub#jupyterhub-debian-packaging) project provides a JupyterHub service including a fully equipped Python3 kernel as a single Debian package – only Python3, NodeJS, and Chromium packages must be installed in addition to the `jupyterhub` one. If you raised an eyebrow on Chromium being in that list, it's used by JavaScript-based visualization frameworks to render PNG images.\n",
    "\n",
    "Including a [NginX-powered SSL off-loader](https://github.com/1and1/debianized-jupyterhub#securing-your-jupyterhub-web-service-with-an-ssl-off-loader), the [complete setup](https://github.com/1and1/debianized-jupyterhub#how-to-set-up-a-simple-service-instance) can be done in under an hour."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1c978e46-5e6e-442d-9c15-65291205c709",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Use-Case: Migration Reporting\n",
    "\n",
    "At the time of this writing (early 2019), a widespread challenge is migration from Oracle Java to other vendors, and also to start migration from Java 8 to newer versions (Java 11). If you do that at scale across many machines and teams, you definitely need some kind of governance, and constant feedback on the current status and the rate of progress."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e51cafdd-aceb-4c49-a3a2-88bd9883dd13",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "What follows is an excerpt from a productive notebook, with anonymized data about [AdoptOpenJDK](https://adoptopenjdk.net/) deployments. That data was originally retrieved from a system called *“Patch Management Reporting”*, which collects information about installed packages for all hosts in the data center. We're in the yellow *“Data Sources”* box of the above figure here.\n",
    "\n",
    "First off, we read the data and show the value sets of categorical columns, plus a sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "18543fb5-a5b5-42f8-8c0e-0a360660eb83",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "raw_data = pd.read_csv(\"../data/cmdb-aoj.csv\", sep=',')\n",
    "print('♯ of Records: {}\\n'.format(len(raw_data)))\n",
    "\n",
    "for name in raw_data.columns[1:]:\n",
    "    if not name.startswith('Last '):\n",
    "        print(name, '=', list(sorted(set(raw_data[name].fillna('')))))\n",
    "\n",
    "print(); print(raw_data.head(3).transpose())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "25d9e0a8-0f29-4ec1-9b4b-10272298a544",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Next comes the usual data cleanup. The `Distribution` column is a bit diverse, and not everyone has Debian codenames and associated major versions memorized. The `map_distro` function fixes that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9c49950f-14cf-4b13-a0f7-bd610a973ccf",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def map_distro(name):\n",
    "    \"\"\"Helper to create canonical OS names.\"\"\"\n",
    "    return (name.split('.', 1)[0]\n",
    "        .replace('Debian 7', 'wheezy')\n",
    "        .replace('Debian 8', 'jessie')\n",
    "        .replace('Debian 9', 'stretch')\n",
    "        .replace('Debian 10', 'buster')\n",
    "        .replace('squeeze', 'Squeeze [6]')\n",
    "        .replace('wheezy', 'Wheezy [7]')\n",
    "        .replace('jessie', 'Jessie [8]')\n",
    "        .replace('stretch', 'Stretch [9]')\n",
    "        .replace('buster', 'Buster [10]')\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "16c5c08b-01e3-414b-9438-e59757a06b4e",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Together with other cleanup steps, the mapper function is applied in a [dfply](https://towardsdatascience.com/dplyr-style-data-manipulation-with-pipes-in-python-380dcb137000) pipeline. The result can be controlled by showing a sample of data points with unique version numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8c103170-0055-4131-a2e6-8a37eb42c980",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from dfply import *\n",
    "\n",
    "cleaned = (raw_data\n",
    "    >> mutate(Version=X['Installed version'].str.split('[()]', 1, expand=True)[0])\n",
    "    >> mutate(Environment=X.Environment\n",
    "              .fillna('--').str.replace('--', 'N/A').str.upper())\n",
    "    >> mutate(Distribution=X.Distribution.apply(map_distro))\n",
    "    >> drop(X.CMDB_Id, X['Last seen'], X['Last modified'], X['Installed version'])\n",
    ")\n",
    "\n",
    "print((cleaned >> distinct(X.Version)).transpose())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1b663319-ddcb-4afc-85c5-cb6969c678eb",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Time to present the cleaned up data, starting with a table of teams and their number of installed packages. In the production notebook, an API of the corporate identity management is used to enrich the table with contact data of the team leads. Having the organizational data available also makes it possible to filter or aggregate the data by business units."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8926ec97-686d-40d3-a2f7-3697b5eb28f9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "counts = cleaned.groupby(['Team']).size()\n",
    "print(counts.reset_index(name='Count'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e84ff887-9a54-4263-9426-6d0825d2d4dc",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "To create a heatmap of how diverse a team's version spectrum is, we calculate percentages of versions per team."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9c9319e1-f864-4ed6-92d9-badb76a58669",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "percentage = cleaned.groupby(['Team', 'Version']).size().reset_index(name='Count')\n",
    "percentage = percentage.assign(Percent=\n",
    "    percentage.apply(lambda x: 100.0 * x[-1] / counts[x[0]], axis=1))\n",
    "print(percentage.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e2b117be-728d-4958-8b5f-709ec1fa2a9e",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "[HoloViews](http://holoviews.org/) makes creating the heatmap including a label overlay a breeze."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e006a75f-ab4c-42c2-964f-38c46aa23c23",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import holoviews as hv\n",
    "hv.extension('bokeh')\n",
    "publish = 1  # publishing or interactive mode?\n",
    "\n",
    "heatmap = hv.HeatMap(percentage[['Version', 'Team', 'Percent', 'Count']]).opts(\n",
    "    hv.opts.HeatMap(\n",
    "        title='Version Distribution by Team',\n",
    "        width=480, xrotation=25, \n",
    "        zlim=(0, 100), cmap='kbc_r', clipping_colors=dict(NaN='#ffffe0'),\n",
    "        colorbar=True, tools=['hover'], toolbar=None if publish else 'right',\n",
    "    )\n",
    ").sort()\n",
    "\n",
    "label_dimension = hv.Dimension('Percent', value_format=lambda x: '%.1f' % x)\n",
    "labels = hv.Labels(heatmap, vdims=label_dimension).opts(\n",
    "    hv.opts.Labels(\n",
    "        text_color='Percent', \n",
    "        text_font_size='10pt',\n",
    "        text_font_style='bold',\n",
    "    )\n",
    ")\n",
    "\n",
    "chart = heatmap * labels\n",
    "\n",
    "if publish:\n",
    "    import time\n",
    "    import phantomjs_bin\n",
    "    from IPython.display import HTML, clear_output\n",
    "\n",
    "    %env BOKEH_PHANTOMJS_PATH={phantomjs_bin.executable_path}\n",
    "    chart_img = 'img/aoj-heatmap.png'\n",
    "    hv.save(chart, chart_img)\n",
    "    chart = HTML('<img src=\"{}?{}\"></img>'.format(chart_img, time.time()))\n",
    "    clear_output()\n",
    "\n",
    "chart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6750b55a-601a-4389-9574-63e8bd2dae3c",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "From the heatmap, you can easily glance whether a team uses predominantly one version, and how recent the used versions are."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9ad5007e-f72d-4287-82c7-fbd764933f29",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Conclusion\n",
    "\n",
    "Using a platform powered by [Project Jupyter](https://twitter.com/ProjectJupyter) and a big chunk of the scientific Python stack lets you easily mold your data into the shape you need, and then choose from a wide range of visualization options to bring your message across."
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {},
   "notebookName": "devops-intelligence",
   "notebookOrigID": 3102685337479740,
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
